{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = input('Input utilize gpu-id (cpu:-1): ')\n",
    "import sys\n",
    "sys.path.append('utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_integer('seq_length', 10,\n",
    "                            \"\"\"seq_length\"\"\")\n",
    "tf.app.flags.DEFINE_integer('seq_start', 4,\n",
    "                            \"\"\" start of seq generation\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_size', 1,\n",
    "                            \"\"\"batch size for training\"\"\")\n",
    "tf.app.flags.DEFINE_integer('height', 128,\n",
    "                            \"\"\"height of input data\"\"\")\n",
    "tf.app.flags.DEFINE_integer('width', 128,\n",
    "                            \"\"\"width of input data\"\"\")\n",
    "tf.app.flags.DEFINE_string('warping', 'bilinear',\n",
    "                            \"\"\"method of warping\"\"\")\n",
    "tf.app.flags.DEFINE_integer('gating_num', 3,\n",
    "                            \"\"\"# of experts\"\"\")\n",
    "tf.app.flags.DEFINE_string('activation', 'softmax',\n",
    "                            \"\"\"gating activation\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('restore_all', True, \n",
    "                            \"\"\"whether restore all or not \"\"\")\n",
    "tf.app.flags.DEFINE_boolean('restore_gating', True, \n",
    "                            \"\"\"whether restore gating or not \"\"\")\n",
    "tf.app.flags.DEFINE_integer('h_conv_ksize', 1,\n",
    "                            \"\"\"kernel size of H\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('trainable_last', True, \n",
    "                            \"\"\"train backtopixel conv(H) of MIM or not\"\"\")\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layer_def as ld\n",
    "from warp import get_pixel_value\n",
    "from warp import bilinear_warp as tf_warp\n",
    "import w_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expert import network_shift\n",
    "from Expert import MIM\n",
    "network_rot = MIM\n",
    "network_grow = MIM\n",
    "from Gating import network_gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_gate = tf.make_template('gate', network_gate)\n",
    "network_shift = tf.make_template('network_convdeconv', network_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model1, model2, model3, model4, model5, test_data):\n",
    "    \"\"\"\n",
    "    model1: model path for translation\n",
    "    model2: model path for rotation\n",
    "    model3: model path for growth/decay\n",
    "    model4: model path for gating\n",
    "    model5: model path for the whole STMoE model\n",
    "    train_data: np.array for test\n",
    "    \"\"\"\n",
    "    x= tf.placeholder(tf.float32, [FLAGS.batch_size, FLAGS.height, FLAGS.width, FLAGS.seq_length])\n",
    "    x_g = []\n",
    "    weights = []\n",
    "    f_g_s = []\n",
    "    x_g_s, x_g_r, x_g_g = [], [], []\n",
    "    \n",
    "    hidden_state_1, hidden_state_diff_1, cell_state_1, cell_state_diff_1, st_memory_1 = [], [], [], [], []\n",
    "    hidden_state_2, hidden_state_diff_2, cell_state_2, cell_state_diff_2, st_memory_2 = [], [], [], [], []       \n",
    "    \n",
    "    for i in range(FLAGS.seq_start - 1):\n",
    "            with tf.variable_scope('expert2'):\n",
    "                inputs = x[:, :, :, i]\n",
    "                inputs = inputs[:, :, :, tf.newaxis]\n",
    "                x_generate_r, hidden_state_1, hidden_state_diff_1, cell_state_1, cell_state_diff_1, st_memory_1 =                     network_grow(inputs, i, hidden_state_1, hidden_state_diff_1, cell_state_1, cell_state_diff_1, st_memory_1, 3, [8, 8, 8], (3, 3), FLAGS.h_conv_ksize, stride=1, tln = True, trainable_last = FLAGS.trainable_last)\n",
    "                \n",
    "            with tf.variable_scope('expert3'):\n",
    "                inputs = x[:, :, :, i]\n",
    "                inputs = inputs[:, :, :, tf.newaxis]\n",
    "                x_generate_g, hidden_state_2, hidden_state_diff_2, cell_state_2, cell_state_diff_2, st_memory_2 =                     network_grow(inputs, i, hidden_state_2, hidden_state_diff_2, cell_state_2, cell_state_diff_2, st_memory_2, 3, [8, 8, 8], (3, 3), FLAGS.h_conv_ksize, stride=1, tln = True, trainable_last = FLAGS.trainable_last)      \n",
    "    \n",
    "    # predict recursively\n",
    "    for i in range(FLAGS.seq_length - FLAGS.seq_start):\n",
    "        print('frame_{}'.format(i))\n",
    "        if i == 0:\n",
    "            with tf.variable_scope('expert1'):\n",
    "                f_generate = network_shift(x[:, :, :, i:i+FLAGS.seq_start])\n",
    "                last_x = x[:, :, :, FLAGS.seq_start - 1]\n",
    "                x_generate_s = tf_warp(last_x[:, :, :, tf.newaxis], f_generate, FLAGS.height, FLAGS.width)\n",
    "                x_generate_s = tf.reshape(x_generate_s[:, :, :, 0], [FLAGS.batch_size, FLAGS.height, FLAGS.width, 1])\n",
    "                x_g_s.append(x_generate_s)\n",
    "\n",
    "            with tf.variable_scope('expert2'):\n",
    "                inputs = x[:, :, :,  FLAGS.seq_start - 1]\n",
    "                inputs = inputs[:, :, :, tf.newaxis]\n",
    "                x_generate_r, hidden_state_1, hidden_state_diff_1, cell_state_1, cell_state_diff_1, st_memory_1 =                      network_grow(inputs, i + FLAGS.seq_start, hidden_state_1, hidden_state_diff_1, cell_state_1, cell_state_diff_1, st_memory_1, 3, [8, 8, 8], (3, 3), FLAGS.h_conv_ksize, stride=1, tln = True, trainable_last = FLAGS.trainable_last)\n",
    "                x_g_r.append(x_generate_r)\n",
    "\n",
    "            with tf.variable_scope('expert3'):\n",
    "                inputs = x[:, :, :,  FLAGS.seq_start - 1]\n",
    "                inputs = inputs[:, :, :, tf.newaxis]\n",
    "                x_generate_g, hidden_state_2, hidden_state_diff_2, cell_state_2, cell_state_diff_2, st_memory_2 =                      network_grow(inputs, i + FLAGS.seq_start, hidden_state_2, hidden_state_diff_2, cell_state_2, cell_state_diff_2, st_memory_2, 3, [8, 8, 8], (3, 3), FLAGS.h_conv_ksize, stride=1, tln = True, trainable_last = FLAGS.trainable_last)\n",
    "                x_g_g.append(x_generate_g)             \n",
    "\n",
    "            with tf.variable_scope('gating_network'):\n",
    "                weight = network_gate(x[:, :, :, i:i+FLAGS.seq_start], FLAGS.gating_num, moe='moe1')\n",
    "                x_sr = tf.concat([x_generate_s, x_generate_r, x_generate_g], axis = -1)\n",
    "                x_generate = weight * x_sr\n",
    "                x_generate = tf.reduce_sum(x_generate, axis=-1)\n",
    "                x_g.append(x_generate)\n",
    "                weights.append(weight)\n",
    "\n",
    "        else:\n",
    "            x_gen = tf.stack(x_g)\n",
    "            print(x_gen.shape)\n",
    "            x_gen = tf.transpose(x_gen, [1, 2, 3, 0])\n",
    "\n",
    "            if i < FLAGS.seq_start:\n",
    "                x_input = tf.concat([x[:, :, :, i:FLAGS.seq_start], x_gen[:,:, :, :i]], axis = 3)\n",
    "            else:\n",
    "                x_input = x_gen[:, :, :, i - FLAGS.seq_start:i]\n",
    "\n",
    "            with tf.variable_scope('expert1'):\n",
    "                f_generate = network_shift(x_input)\n",
    "                last_x = x_g[-1]\n",
    "                x_generate_s = tf_warp(last_x[:, :, :, tf.newaxis], f_generate,  FLAGS.height, FLAGS.width)\n",
    "                x_generate_s = tf.reshape(x_generate_s[:, :, :, 0], [FLAGS.batch_size, FLAGS.height, FLAGS.width, 1])\n",
    "                x_g_s.append(x_generate_s)\n",
    "\n",
    "            with tf.variable_scope('expert2'):\n",
    "                inputs = x_g[-1]\n",
    "                inputs = inputs[:, :, :, tf.newaxis]\n",
    "                x_generate_r, hidden_state_1, hidden_state_diff_1, cell_state_1, cell_state_diff_1, st_memory_1 =                      network_grow(inputs, i + FLAGS.seq_start, hidden_state_1, hidden_state_diff_1, cell_state_1, cell_state_diff_1, st_memory_1, 3, [8, 8, 8], (3, 3), FLAGS.h_conv_ksize, stride=1, tln = True, trainable_last = FLAGS.trainable_last)\n",
    "                x_g_r.append(x_generate_r)\n",
    "\n",
    "            with tf.variable_scope('expert3'):\n",
    "                inputs = x_g[-1]\n",
    "                inputs = inputs[:, :, :, tf.newaxis]\n",
    "                x_generate_g, hidden_state_2, hidden_state_diff_2, cell_state_2, cell_state_diff_2, st_memory_2 =                      network_grow(inputs, i + FLAGS.seq_start, hidden_state_2, hidden_state_diff_2, cell_state_2, cell_state_diff_2, st_memory_2, 3, [8, 8, 8], (3, 3), FLAGS.h_conv_ksize, stride=1, tln = True, trainable_last = FLAGS.trainable_last)\n",
    "                x_g_g.append(x_generate_g) \n",
    "\n",
    "            with tf.variable_scope('gating_network'):\n",
    "                weight = network_gate(x_input, FLAGS.gating_num, moe='moe1')\n",
    "                x_sr = tf.concat([x_generate_s, x_generate_r, x_generate_g], axis = -1)\n",
    "                x_generate = weight*x_sr\n",
    "                x_generate = tf.reduce_sum(x_generate, axis=-1)\n",
    "                x_g.append(x_generate) \n",
    "                weights.append(weight)\n",
    "                \n",
    "    x_g = tf.stack(x_g)\n",
    "    x_g = tf.transpose(x_g, [1, 2, 3, 0])\n",
    "\n",
    "    weights = tf.stack(weights)\n",
    "    weights = tf.transpose(weights, [1, 0, 2, 3, 4])\n",
    "    \n",
    "    # build a saver \n",
    "    expert1_varlist = {v.op.name.lstrip(\"expert1/\"): v \n",
    "          for v in tf.get_collection(tf.GraphKeys.VARIABLES, scope=\"expert1/\")} \n",
    "\n",
    "    expert1_saver = tf.train.Saver(var_list=expert1_varlist) \n",
    "    \n",
    "    expert2_varlist = {v.op.name[8:]: v \n",
    "          for v in tf.get_collection(tf.GraphKeys.VARIABLES, scope=\"expert2/\")} \n",
    "    expert2_saver = tf.train.Saver(var_list=expert2_varlist) \n",
    "    \n",
    "    expert3_varlist = {v.op.name[8:]: v \n",
    "          for v in tf.get_collection(tf.GraphKeys.VARIABLES, scope=\"expert3/\")} \n",
    "    expert3_saver = tf.train.Saver(var_list=expert3_varlist)   \n",
    "    \n",
    "    # build a gating saver\n",
    "    gating_varlist = {v.name.lstrip(\"gating_network/\"): v \n",
    "           for v in tf.get_collection(tf.GraphKeys.VARIABLES, scope=\"gating_network/\")} \n",
    "    gating_saver = tf.train.Saver(var_list=gating_varlist, max_to_keep=100)    \n",
    "    \n",
    "    # MSE loss\n",
    "    MSE = tf.losses.mean_squared_error(x[:, :, :, FLAGS.seq_start:], x_g[:, :, :, :])\n",
    "    \n",
    "    # SSIM\n",
    "    SSIM = tf.image.ssim(x[:, :, :, FLAGS.seq_start:], x_g[:, :, :, :], 1)\n",
    "\n",
    "    # List of all varables\n",
    "    variables = tf.global_variables()\n",
    "\n",
    "    # strat rinning operations on Graph\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('init netwrok from scratch....')\n",
    "    sess.run(init)\n",
    "                         \n",
    "    expert1_saver.restore(sess, model1)\n",
    "\n",
    "    expert2_saver.restore(sess, model2)\n",
    "    \n",
    "    expert3_saver.restore(sess, model3)\n",
    "    \n",
    "    # restore gating saver\n",
    "    if FLAGS.restore_gating:\n",
    "        gating_saver.restore(sess, model4)\n",
    "    \n",
    "    # restore all saver\n",
    "    all_saver =  tf.train.Saver(max_to_keep=100)\n",
    "    \n",
    "    if FLAGS.restore_all:\n",
    "        all_saver.restore(sess, model5)\n",
    "            \n",
    "    Loss_MSE, Loss_MSE_v  = [], []\n",
    "    all_Loss, all_Loss_v = [], []\n",
    "    Pred, Pred_s, Pred_r, Pred_g, Pred_t, W_pre, Loss, SSIM_test  = [], [], [], [], [], [], [], []\n",
    "    # test\n",
    "    for i, da in enumerate(test_data):\n",
    "        batch_x = da[np.newaxis, :, :, :]\n",
    "        batch_x = batch_x.transpose(0, 2, 3, 1)\n",
    "        pred, pred_s, pred_r, pred_g, w_pre, mse_test, ssim_test = sess.run([x_g, x_g_s, x_g_r, x_g_g, weights, MSE, SSIM],\n",
    "                                                                                     feed_dict = {x:batch_x}) \n",
    "        \n",
    "        Pred.append(pred)\n",
    "        Pred_s.append(pred_s)\n",
    "        Pred_r.append(pred_r)\n",
    "        Pred_g.append(pred_g)      \n",
    "        W_pre.append(w_pre)\n",
    "        Loss.append(mse_test)\n",
    "        SSIM_test.append(ssim_test)\n",
    "        \n",
    "        \n",
    "    return Pred, Pred_s, Pred_r, Pred_g, W_pre, Loss, SSIM_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model1 = './models/STMoE-1_trans'\n",
    "    model2 = './models/STMoE-1_rot'\n",
    "    model3 = './models/STMoE-1_grow' \n",
    "    model4 = './models/STMoE-1_gating'\n",
    "    model5 = './models/STMoE-1_all'\n",
    "\n",
    "\n",
    "    test_data = np.load('./data/test_data.npy')\n",
    "    max_intensity = 255\n",
    "        \n",
    "    test_data = test_data / max_intensity\n",
    "    Pred, Pred_s, Pred_r, Pred_g, W_pre, Loss, SSIM_test = test(model1, model2, model3, model4, model5, test_data)\n",
    "    \n",
    "    return Pred, Pred_s, Pred_r, Pred_g, W_pre, Loss, SSIM_test, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    Pred, Pred_s, Pred_r, Pred_g, W_pre, Loss, SSIM_test, test_data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = np.array(Loss)*255**2\n",
    "Loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSIM = np.array(SSIM_test)\n",
    "SSIM.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = np.array(Pred)*255\n",
    "Pred = Pred[:, 0, :, :, :]\n",
    "test_data = test_data*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 79\n",
    "vmx = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pred vs gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(FLAGS.seq_length):   \n",
    "    if i >= FLAGS.seq_start:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(Pred[num, :, :, i-FLAGS.seq_start], vmin = 0, vmax = vmx, cmap = 'jet') \n",
    "        plt.title('est_{}'.format(i))\n",
    "        plt.colorbar()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(test_data[num, i, :, :], vmin = 0, vmax = vmx, cmap = 'jet')   \n",
    "    plt.title('gt_{}'.format(i))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(FLAGS.seq_length):   \n",
    "    if i >= FLAGS.seq_start:\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow(Pred[num, :, :, i-FLAGS.seq_start], vmin = 0, vmax = vmx, cmap = 'jet') \n",
    "        plt.title('est_{}'.format(i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred and contribution of each experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_pre = np.array(W_pre)\n",
    "W_pre.shape\n",
    "W_pre = W_pre[:, 0, :, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums =  [79]\n",
    "k = ['translation', 'rot', 'g/d']\n",
    "axes = []\n",
    "fig=plt.figure(figsize=(12, 9))\n",
    "for i, n in enumerate(nums):\n",
    "    for j in range(3):\n",
    "        axes.append(fig.add_subplot(4, 4, ((4*i+j+1))))\n",
    "        plt.imshow(Pred[n, :, :, 1], cmap ='jet', vmin=0, vmax=vmx)\n",
    "        plt.imshow(W_pre[n, 1, :, :, j], alpha=0.4, vmax=0.8)\n",
    "        plt.title(k[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
